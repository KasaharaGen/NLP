Q: How do I use FTP via the command line to download all files? I tried to use Filezilla and Cyberduck for file transfer over a simple FTP server. The problems I have is:


*

*Filezilla: When I use it for file transferring, I check the "Activity Monitor", the "% CPU" usage is like 150% - 200%. I was shocked. My mac start to become lag, so I stop it.

*Cyberduck: When I download a folder from ftp, about 60mb, inside have small files (*.php, *.jpg etc). It took about 8 hours to download the files(there is a time indication of how much time left in cyberduck). If I use filezilla, it only takes about 1-3 mins. I notice, when using Cyberduck, it keep setting the permissions first, not really transfer the files directly. And it took quite long.
Thus, I went to google, and I found that mac can use Terminal to connect to ftp server and download files.
ftp hostname
mget * (download all the files)

Now, another problem, let say, in my ftp I have:
- blog(folder)
    - php(folder)
    - img(folder)
- others folder

I want to download "blog" and its subsequent folders and files. Can I do it in 1 command line? If no, how do you download my "blog" folder?
I remember in unix/linux command, there is something like this:
- remove -R blba

which remove the folder blba recursively (its subsequent folders and files), I wonder if mac's terminal ftp command can support this.
Please advise 

A: The curl program could help you download an FTP file, but it specializes in one-off URLs (http, ftp, etc). It is possible to use Perl to script something up to list then download, but its much easier to use wget! 
However, wget is not a standard program of OSX so you will need to manually download, compile, and install it (relatively easy task, as long as you have Xcode installed.)


*

*Install Xcode from the App Store.

*Download wget source

*Open a Terminal into the directory you saved the source.


Run the following commands:
    $ tar xfvz wget-latest.tar.gz
    $ cd wget-*
    $ ./configure && make

The wget binary will be produced in a src subdirectory. From here you can run the binary directly as ./src/wget or install into /usr/local/bin:
    $ sudo make install

Now, you only need to run wget -r  ftp://username:passwd@server/path/to/download and your FTP site will be recursively downloaded from that path!
Just remember that the /path/to/download is relative to the username you login with... and FTP passwords are notoriously unsecure :)

A: If you want to proceed without Xcode you may also use curlmirror which builds on curl which is already supplied with OSX. In case you get the script from the web site linked above, you have to rename the first line to #!/usr/bin/perl in a text editor of your choice.

A: the standard ftp doesn't have "recursive download" functionality. but ncftp has.  Please try it.

A: I suggest you switch to the latest snapshot build of Cyberduck which should improve download transfer initialization.
